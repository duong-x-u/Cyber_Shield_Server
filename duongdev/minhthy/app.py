import sys
import os

# Th√™m parent directory v√†o path n·∫øu c·∫ßn
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from flask import Flask, render_template, request, jsonify, Response
from flask_socketio import SocketIO, emit, join_room, leave_room
from bytez import Bytez
from datetime import datetime, timezone, timedelta
from datetime import time as dt_time
import time as pytime
import json
import re
import threading
import random
from .database import (
    create_conversation, get_all_conversations, get_conversation,
    update_conversation, delete_conversation, save_message, get_messages,
    get_message, update_message_reactions, retract_message, edit_message, mark_messages_seen,
    search_messages, get_message_count, get_setting, update_setting,
    get_all_settings, export_conversation, get_latest_global_message_time,
    save_daily_summary, get_summary_for_date
)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'minh-thy-secret-2025'

socketio = SocketIO(
    app,
    cors_allowed_origins="*",
    ping_timeout=60,
    ping_interval=25,
    max_http_buffer_size=30 * 1024 * 1024, # 30MB limit for images
    logger=False,
    engineio_logger=False
)

# Lock to ensure background tasks are started only once
_tasks_started_lock = threading.Lock()
_tasks_started = False
# ========== BYTEZ SETUP ==========
BYTEZ_API_KEY = "YOUR_API_KEY"  # Thay API key c·ªßa b·∫°n
sdk = Bytez("4bf720ec73b4b1af0fb1783e9667fe07")
model = sdk.model("google/gemini-2.5-flash")

# Separate model for summarization
summary_sdk = Bytez("69a7f91e34d73159934218beb9296b04")
summary_model = summary_sdk.model("google/gemini-2.5-flash")

GMT7 = timezone(timedelta(hours=7))

life_events = [
    ("Ph·ª• m·∫π d·ªçn nh√†", 20, 45), ("ƒêi t·∫Øm", 15, 25),
    ("H·ªçc b√†i th√™m", 45, 90), ("ƒêi xem phim v·ªõi b·∫°n", 120, 180),
    ("L√†m b√†i t·∫≠p", 30, 60), ("ƒêi mua ƒë·ªì ƒÉn v·∫∑t", 10, 20)
]
life_event_names = [event[0] for event in life_events]

# Constants for schedule (can be moved to a config later)
SCHOOL_START_HOUR = 7
SCHOOL_END_HOUR = 11
SCHOOL_END_MINUTE = 30 # For 11:30

def time_since_last_message(last_message_time_str):
    if last_message_time_str:
        try:
            last_message_dt = datetime.strptime(last_message_time_str, '%Y-%m-%d %H:%M:%S').replace(tzinfo=GMT7)
            time_diff_minutes = (datetime.now(GMT7) - last_message_dt).total_seconds() / 60
            return int(time_diff_minutes)
        except ValueError:
            pass
    return 0

def life_and_school_scheduler():
    while True:
        current_dt = datetime.now(GMT7)
        current_hour = current_dt.hour
        current_minute = current_dt.minute
        weekday = current_dt.weekday() # Monday is 0, Sunday is 6
        now_time = current_dt.time()

        conversations = get_all_conversations()
        for conv in conversations:
            conv_id = conv['id']
            current_busy_status = conv.get('busy_status', 'r·∫£nh')
            current_busy_until = conv.get('busy_until')

            temp_new_busy_status = 'r·∫£nh'
            temp_new_busy_until = None

            # --- 1. Check if an active temporary busy status (custom random event or 'ƒêang ·ªëm') is still valid ---
            if current_busy_status in life_event_names or current_busy_status == 'ƒêang ·ªëm':
                if current_busy_until:
                    try:
                        busy_until_dt = datetime.strptime(current_busy_until, '%Y-%m-%d %H:%M:%S').replace(tzinfo=GMT7)
                        if current_dt < busy_until_dt:
                            # Event is still active, maintain it
                            temp_new_busy_status = current_busy_status
                            temp_new_busy_until = current_busy_until
                    except (ValueError, TypeError):
                        pass # Parsing error, will default to r·∫£nh later

            # --- 2. If currently 'r·∫£nh' (or previous temporary status expired), check for NEW 'ƒêang ·ªëm' status ---
            # This is a daily random chance to become sick, typically triggers once early morning
            # Only if not already sick or in another temporary event
            if temp_new_busy_status == 'r·∫£nh' and current_busy_status != 'ƒêang ·ªëm' and \
               random.random() < 0.01 and now_time.hour == 6 and current_minute < 5: # 1% chance daily, early morning
                sick_duration_hours = random.randint(2, 6) # Sick for 2-6 hours
                sick_until_dt = current_dt + timedelta(hours=sick_duration_hours)
                temp_new_busy_status = 'ƒêang ·ªëm'
                temp_new_busy_until = sick_until_dt.strftime('%Y-%m-%d %H:%M:%S')

            # --- 3. If still 'r·∫£nh', check fixed schedules (School, Nap), but allow random skips ---
            if temp_new_busy_status == 'r·∫£nh': # Only if not in a temporary status or sick
                # Random chance to skip fixed events
                skip_school_today = random.random() < 0.05 # 5% chance to skip school
                skip_nap_today = random.random() < 0.05 # 5% chance to skip nap

                # School
                if not skip_school_today and weekday <= 5 and dt_time(SCHOOL_START_HOUR, 0) <= now_time <= dt_time(SCHOOL_END_HOUR, SCHOOL_END_MINUTE):
                    temp_new_busy_status = 'H·ªçc ch√≠nh kh√≥a'
                    temp_new_busy_until = current_dt.replace(hour=SCHOOL_END_HOUR, minute=SCHOOL_END_MINUTE, second=0, microsecond=0).strftime('%Y-%m-%d %H:%M:%S')
                # Nap
                elif not skip_nap_today and dt_time(13, 15) <= now_time <= dt_time(15, 0):
                    temp_new_busy_status = 'Ng·ªß tr∆∞a'
                    temp_new_busy_until = current_dt.replace(hour=15, minute=0, second=0, microsecond=0).strftime('%Y-%m-%d %H:%M:%S')
        

            # --- Final update for busy status ---
            if temp_new_busy_status != current_busy_status or temp_new_busy_until != current_busy_until:
                
                # Check if a new busy event is starting (and it's not just becoming 'r·∫£nh' or 'ƒêang ng·ªß')
                is_starting_new_event = (
                    temp_new_busy_status != 'r·∫£nh' and
                    temp_new_busy_status != 'ƒêang ng·ªß' and
                    temp_new_busy_status != current_busy_status
                )

                if is_starting_new_event:
                    # Announce the event first
                    announcement = get_event_announcement_message(conv_id, temp_new_busy_status)
                    if announcement:
                        send_proactive_ai_message(conv_id, announcement)
                        socketio.sleep(random.uniform(2, 5)) # Pause before officially becoming busy

                update_kwargs = {
                    'busy_status': temp_new_busy_status,
                    'busy_until': temp_new_busy_until
                }
                # If Minh Thy just became 'r·∫£nh' from a busy state, record what she was busy with
                if temp_new_busy_status == 'r·∫£nh' and current_busy_status != 'r·∫£nh':
                    update_kwargs['last_busy_reason'] = current_busy_status
                else:
                    # If she is still busy or becoming busy, or if she was already r·∫£nh (no meaningful transition)
                    # clear last_busy_reason to avoid stale data
                    update_kwargs['last_busy_reason'] = None
                    
                update_conversation(conv_id, **update_kwargs)
                socketio.emit('conversations_updated', {'conversations': get_all_conversations()})

            # --- SLEEP LOGIC ---
            # This part remains largely unchanged, but needs to react to 'ƒêang ·ªëm'
            current_sleep_status = conv.get('sleep_status', 'th·ª©c')
            last_sender_role = conv.get('last_sender_role')

            # 1. Ask to sleep (22:20 - 23:59)
            if (current_hour == 22 and current_minute >= 20) or (current_hour == 23):
                if current_sleep_status == 'th·ª©c' and last_sender_role == 'user':
                    try:
                        ai_action = get_proactive_sleep_message(conv_id)
                        raw_content = ai_action.get('content', '')
                        contents_to_send = []
                        if isinstance(raw_content, str) and raw_content.strip():
                            contents_to_send.append(raw_content.strip())
                        elif isinstance(raw_content, list):
                            contents_to_send.extend(item for item in raw_content if isinstance(item, str) and item.strip())
                        if contents_to_send:
                            for content in contents_to_send:
                                ai_msg_id = save_message(conv_id, 'assistant', conv['ai_name'], content)
                                socketio.emit('new_message', {
                                    'id': ai_msg_id, 'role': 'assistant', 'sender_name': conv['ai_name'],
                                    'content': content, 'timestamp': datetime.now(GMT7).strftime('%H:%M'), 'is_seen': 0
                                }, room=str(conv_id))
                                socketio.sleep(0.1)
                            update_conversation(conv_id, sleep_status='ƒë√£ h·ªèi')
                            socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
                    except Exception as e:
                        print(f"‚ùå Error sending proactive sleep message for conv {conv_id}: {e}")

            # 2. Force sleep (00:30 - 05:00)
            # If sick, don't force sleep, sickness overrides sleep
            if (current_hour == 0 and current_minute >= 30) or (current_hour > 0 and current_hour < 5):
                if current_sleep_status != 'ng·ªß say' and temp_new_busy_status != 'ƒêang ·ªëm':
                    update_conversation(conv_id, sleep_status='ng·ªß say', busy_status='ƒêang ng·ªß')
                    socketio.emit('conversations_updated', {'conversations': get_all_conversations()})

            # 3. Wake up
            # If sick, don't wake up from normal sleep, sickness overrides
            if current_sleep_status == 'ng·ªß say' and temp_new_busy_status != 'ƒêang ·ªëm':
                is_weekday = 0 <= weekday <= 5
                is_sunday = weekday == 6
                weekday_wakeup = is_weekday and (current_hour >= 5 and current_hour < SCHOOL_START_HOUR)
                sunday_wakeup = is_sunday and (current_hour > 9 or (current_hour == 9 and current_minute >= 30))
                if weekday_wakeup or sunday_wakeup:
                    update_conversation(conv_id, sleep_status='th·ª©c', busy_status='r·∫£nh')
                    socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
        socketio.sleep(60)

def presence_updater_scheduler():
    while True:
        socketio.sleep(60)
        
        conversations = get_all_conversations()
        if not conversations:
            continue
        conv = conversations[0]

        last_message_time_str = get_latest_global_message_time()
        minutes_ago = time_since_last_message(last_message_time_str)
        is_active_from_messages = minutes_ago < 4

        # New "lurking" logic: 5% chance per minute to appear online if idle
        is_lurking = False
        if not is_active_from_messages and random.random() < 0.05:
            # Only lurk if not in a "do-not-disturb" state
            if conv.get('sleep_status') == 'th·ª©c' and conv.get('busy_status') not in ['H·ªçc ch√≠nh kh√≥a', 'ƒêang ng·ªß', 'ƒêi t·∫Øm', 'ƒêi xem phim v·ªõi b·∫°n']:
                print("üëÄ AI is lurking... coming online for a moment.")
                is_lurking = True

        global_status = 'online' if is_active_from_messages or is_lurking else 'offline'
        
        # If offline, use real minutes_ago, otherwise show as currently active
        final_minutes_ago = 0 if global_status == 'online' else minutes_ago

        socketio.emit('ai_presence_updated', {
            'status': global_status,
            'minutes_ago': final_minutes_ago
        })
        
        # Logic c·∫≠p nh·∫≠t mood v·∫´n d·ª±a tr√™n conversations[0] (cu·ªôc tr√≤ chuy·ªán g·∫ßn nh·∫•t), ƒëi·ªÅu n√†y h·ª£p l√Ω
        if random.random() < 0.02:
            conv_id = conv['id']
            current_mood = int(conv.get('mood', 70))
            mood_change_amount = random.randint(-5, 5)
            new_mood = max(0, min(100, current_mood + mood_change_amount))
            if new_mood != current_mood:
                update_conversation(conv_id, mood=new_mood)
                socketio.emit('mood_updated', {'conv_id': conv_id, 'new_mood': new_mood})

def proactive_message_scheduler():
    while True:
        socketio.sleep(30 * 60) # Check every 30 minutes
        current_hour = datetime.now(GMT7).hour
        if 0 <= current_hour < 7: # Skip between 00:00 and 07:00 (late night/early morning)
            continue

        conversations = get_all_conversations()
        if not conversations:
            continue
            
        # Only apply proactive message logic to the most recent conversation
        conv = conversations[0] 

        if conv.get('last_sender_role') == 'user':
            try:
                time_diff = (datetime.now(GMT7) - datetime.strptime(conv['last_message_time'], '%Y-%m-%d %H:%M:%S').replace(tzinfo=GMT7)).total_seconds()
                if time_diff > (5 * 3600): # If idle for more than 5 hours
                    ai_action = get_proactive_ai_response(conv['id'])
                    raw_content = ai_action.get('content', '')
                    contents_to_send = []
                    if isinstance(raw_content, str) and raw_content.strip():
                        contents_to_send.append(raw_content.strip())
                    elif isinstance(raw_content, list):
                        contents_to_send.extend(item for item in raw_content if isinstance(item, str) and item.strip())
                    
                    if contents_to_send:
                        for i, content in enumerate(contents_to_send):
                            typing_delay = max(0.5, len(content) * 0.05 + random.uniform(0.1, 0.5)) + (random.uniform(0.3, 1.0) if i > 0 else 0)
                            socketio.emit('typing_start', room=str(conv['id']))
                            socketio.sleep(typing_delay)
                            socketio.emit('typing_stop', room=str(conv['id']))
                            ai_msg_id = save_message(conv['id'], 'assistant', conv['ai_name'], content)
                            socketio.emit('new_message', {
                                'id': ai_msg_id, 'role': 'assistant', 'sender_name': conv['ai_name'], 'content': content,
                                'timestamp': datetime.now(GMT7).strftime('%H:%M'), 'is_seen': 0
                            }, room=str(conv['id']))
                            socketio.sleep(0.1)
                        socketio.emit('ai_presence_updated', {'status': 'online', 'minutes_ago': 0})
                        socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
            except Exception as e:
                print(f"‚ùå Error sending proactive message for conv {conv['id']}: {e}")

def daily_summary_scheduler():
    """
    Runs once a day to summarize the conversation and save it as long-term memory.
    """
    while True:
        now = datetime.now(GMT7)
        # Set the target time for today (e.g., 23:59:00)
        next_run = now.replace(hour=23, minute=59, second=0, microsecond=0)
        
        if now > next_run:
            # If it's already past 23:59, schedule for tomorrow
            next_run += timedelta(days=1)
            
        wait_seconds = (next_run - now).total_seconds()
        print(f"üóìÔ∏è Daily Summary Task: Next summary scheduled in {wait_seconds / 3600:.2f} hours.")
        socketio.sleep(wait_seconds)

        try:
            print(f"üß† Running daily summary for {now.strftime('%Y-%m-%d')}...")
            
            # For simplicity, we summarize the first/main conversation
            all_convs = get_all_conversations()
            if not all_convs:
                print("DBSummary: No conversations to summarize.")
                continue
                
            conv_to_summarize = all_convs[0]
            conv_id = conv_to_summarize['id']
            
            # 1. Get all messages from today
            today_str = now.strftime('%Y-%m-%d')
            start_of_day = f"{today_str} 00:00:00"
            end_of_day = f"{today_str} 23:59:59"
            
            messages_today = get_messages(conv_id, start_date=start_of_day, end_date=end_of_day)
            
            if not messages_today or len(messages_today) < 10: # Don't summarize short chats
                print(f"DBSummary: Not enough messages in conv {conv_id} for {today_str} to summarize.")
                continue

            # 2. Format messages into a log
            chat_log = "\n".join([f"{msg['sender_name']}: {msg['content']}" for msg in messages_today])
            
            # 3. Create a prompt for the summarization model
            summary_prompt = f"""D·ª±a v√†o ƒëo·∫°n h·ªôi tho·∫°i sau, h√£y t√≥m t·∫Øt l·∫°i nh·ªØng th√¥ng tin quan tr·ªçng nh·∫•t trong ng√†y d∆∞·ªõi d·∫°ng g·∫°ch ƒë·∫ßu d√≤ng. Ch·ªâ t·∫≠p trung v√†o:
- Nh·ªØng s·ª± ki·ªán, k·∫ø ho·∫°ch, ho·∫∑c th√¥ng tin c√° nh√¢n quan tr·ªçng m√† user ƒë√£ chia s·∫ª (v√≠ d·ª•: t√™n, tu·ªïi, s·ªü th√≠ch, n∆°i ·ªü, c√¥ng vi·ªác, chuy·ªán gia ƒë√¨nh, k·∫ø ho·∫°ch s·∫Øp t·ªõi).
- C·∫£m x√∫c ch√≠nh c·ªßa user trong ng√†y (vui, bu·ªìn, t·ª©c gi·∫≠n, lo l·∫Øng).
- Nh·ªØng c√¢u chuy·ªán c∆∞·ªùi ho·∫∑c chi ti·∫øt ƒë√°ng nh·ªõ ƒë√£ t·∫°o n√™n ƒëi·ªÉm nh·∫•n cho cu·ªôc tr√≤ chuy·ªán.
- T√™n ri√™ng, ƒë·ªãa ƒëi·ªÉm, ho·∫∑c c√°c th√¥ng tin c·ª• th·ªÉ ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.

B·ªè qua nh·ªØng c√¢u ch√†o h·ªèi v√† c√°c ƒëo·∫°n h·ªôi tho·∫°i th√¥ng th∆∞·ªùng, v√¥ nghƒ©a. Tr·∫£ l·ªùi ng·∫Øn g·ªçn.

ƒêO·∫†N H·ªòI THO·∫†I:
---
{chat_log}
---

B·∫¢N T√ìM T·∫ÆT:
"""
            
            # 4. Call the summary model
            summary_messages = [{"role": "user", "content": summary_prompt}]
            result = summary_model.run(summary_messages)

            if result[1]: raise Exception(result[1])
            summary_text = result[0].get('content', '').strip()

            if summary_text:
                # 5. Save the summary
                save_daily_summary(today_str, summary_text)
                print(f"‚úÖ Successfully saved summary for {today_str}. Content: {summary_text[:150]}...")
            else:
                print("DBSummary: Model returned an empty summary.")

        except Exception as e:
            print(f"‚ùå Error in daily_summary_scheduler: {e}")
            
        # Sleep for a bit to ensure we don't run again in the same minute
        socketio.sleep(60)


def random_life_events_scheduler():
    """Periodically triggers random 'life events' to make the AI seem busier."""
    while True:
        # Check every 20 minutes
        socketio.sleep(20 * 60)

        # 15% chance to trigger a random event
        if random.random() < 0.15:
            convs = get_all_conversations()
            if not convs: continue
            conv = convs[0] # Apply to the main conversation for now

            # Only trigger if the AI is currently 'r·∫£nh' (not in school, sleeping, etc.)
            if conv.get('busy_status') == 'r·∫£nh' and conv.get('sleep_status') == 'th·ª©c':
                event_name, min_d, max_d = random.choice(life_events)
                duration_minutes = random.randint(min_d, max_d)

                now = datetime.now(GMT7)
                busy_until_dt = now + timedelta(minutes=duration_minutes)
                busy_until_str = busy_until_dt.strftime('%Y-%m-%d %H:%M:%S')

                # Announce the event first
                announcement = get_event_announcement_message(conv['id'], event_name)
                if announcement:
                    send_proactive_ai_message(conv['id'], announcement)
                    socketio.sleep(random.uniform(2, 5)) # Pause to make it feel like the AI sent message then went busy

                # Then update the status
                update_conversation(conv['id'], busy_status=event_name, busy_until=busy_until_str)
                socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
                print(f"üéâ New Life Event for conv {conv['id']}: {event_name} for {duration_minutes} minutes.")

def start_background_tasks_if_needed():
    global _tasks_started
    with _tasks_started_lock:
        if not _tasks_started:
            print("="*50 + "\nüöÄ Starting background tasks for Minh Thy...\n" + "="*50)
            socketio.start_background_task(proactive_message_scheduler)
            socketio.start_background_task(presence_updater_scheduler)
            socketio.start_background_task(life_and_school_scheduler)
            socketio.start_background_task(random_life_events_scheduler)
            socketio.start_background_task(daily_summary_scheduler)
            _tasks_started = True
            print("‚úÖ Background tasks started.")

def get_system_prompt(conv_id):
    conv = get_conversation(conv_id)
    if not conv: return "" 
    
    ai_name, user_name, mood = conv['ai_name'], conv['user_name'], conv['mood']
    busy_status = conv.get('busy_status', 'r·∫£nh')
    last_busy_reason = conv.get('last_busy_reason') # Retrieve the new field

    # Get yesterday's summary to inject into the prompt
    yesterday = datetime.now(GMT7) - timedelta(days=1)
    yesterday_str = yesterday.strftime('%Y-%m-%d')
    yesterday_summary = get_summary_for_date(yesterday_str)
    
    summary_prompt = ""
    if yesterday_summary:
        summary_prompt = f"--- üìù T√ìM T·∫ÆT H√îM QUA:\n{yesterday_summary}\n---"

    # Add a section for last_busy_reason if it exists
    recent_activity_prompt = ""
    if last_busy_reason:
        # Map busy reasons to more natural language for intro
        reason_map = {
            'H·ªçc ch√≠nh kh√≥a': 'v·ª´a h·ªçc xong',
            'Ng·ªß tr∆∞a': 'v·ª´a ng·ªß tr∆∞a d·∫≠y',
            'ƒêang ·ªëm': 'v·ª´a h·∫øt ·ªëm', # Special case: just recovered from being sick
            'Ph·ª• m·∫π d·ªçn nh√†': 'v·ª´a ph·ª• m·∫π d·ªçn nh√† xong',
            'ƒêi t·∫Øm': 'v·ª´a t·∫Øm xong',
            'H·ªçc b√†i th√™m': 'v·ª´a h·ªçc b√†i th√™m xong',
            'ƒêi xem phim v·ªõi b·∫°n': 'v·ª´a ƒëi xem phim v·ªÅ',
            'L√†m b√†i t·∫≠p': 'v·ª´a l√†m b√†i t·∫≠p xong',
            'ƒêi mua ƒë·ªì ƒÉn v·∫∑t': 'v·ª´a ƒëi mua ƒë·ªì ƒÉn v·∫∑t v·ªÅ'
        }
        friendly_reason = reason_map.get(last_busy_reason, 'v·ª´a xong vi·ªác')
        recent_activity_prompt = f"B·∫†N {friendly_reason.upper()}. H√£y th·ªÉ hi·ªán s·ª± m·ªát m·ªèi, tho·∫£i m√°i ho·∫∑c b·∫•t k·ª≥ c·∫£m x√∫c n√†o li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông ƒë√≥ TR∆Ø·ªöC KHI tr·∫£ l·ªùi tin nh·∫Øn c·ªßa user. V√ç D·ª§: 'O√°p, d·ªçn nh√† m·ªát x·ªâu √°!', 'Cu·ªëi c√πng c≈©ng xong b√†i t·∫≠p, h√∫ h·ªìn!'. B·∫°n ch·ªâ c·∫ßn l√†m ƒëi·ªÅu n√†y m·ªôt l·∫ßn. (H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông x√≥a th√¥ng tin n√†y sau khi b·∫°n tr·∫£ l·ªùi)."

    context_behavior_rules = {
        'H·ªçc ch√≠nh kh√≥a': "B·∫†N ƒêANG TRONG GI·ªú H·ªåC CH√çNH KH√ìA. N·∫øu user nh·∫Øn, ch·ªâ tr·∫£ l·ªùi m·ªôt l·∫ßn duy nh·∫•t b·∫±ng m·ªôt tin nh·∫Øn c·ª±c ng·∫Øn g·ªçn nh∆∞ 'ƒëang h·ªçc', 'h·ªçc b√†i', 't√≠ rep' r·ªìi IM L·∫∂NG.",
        'Ng·ªß tr∆∞a': "B·∫†N ƒêANG NG·ª¶ TR∆ØA. H√ÉY TR·∫¢ L·ªúI NH∆Ø ƒêANG NG·ª¶ M∆†. D√ôNG T·ª™ NG·ªÆ NG·∫ÆN G·ªåN, L·ªòN X·ªòN, KH√îNG R√ï NGHƒ®A, TH·ªÇ HI·ªÜN S·ª∞ M∆† M√ÄNG, NG√ÅI NG·ª¶. V√ç D·ª§: '∆∞m... b√°nh tr√°ng...', 'g√¨ d·ª£... cho ng·ªß mi·∫øng...', '·ªìn √†o qu√°...'",
        'ƒêang ng·ªß': "HI·ªÜN T·∫†I B·∫†N ƒêANG NG·ª¶. N·∫æU B·ªä ƒê√ÅNH TH·ª®C, H√ÉY TR·∫¢ L·ªúI C√ÄU NH√ÄU, KH√ì CH·ªäU, V·ªöI T·ª™ NG·ªÆ U·ªÇ O·∫¢I, NG·∫ÆN G·ªåN. KH√îNG S·ª¨ D·ª§NG EMOJI.",
        'ƒêang ·ªëm': "B·∫†N ƒêANG B·ªä ·ªêM. H√ÉY TR·∫¢ L·ªúI V·ªöI GI·ªåNG ƒêI·ªÜU Y·∫æU ·ªöT, THAN V√ÉN, CH·ªà MU·ªêN NGH·ªà NG∆†I. S·ª¨ D·ª§NG √çT EMOJI HO·∫∂C EMOJI BU·ªíN B√É, M·ªÜT M·ªéI.",
        'Ph·ª• m·∫π d·ªçn nh√†': "B·∫†N ƒêANG PH·ª§ M·∫∏ D·ªåN NH√Ä. H√ÉY TR·∫¢ L·ªúI R·∫§T NG·∫ÆN G·ªåN, ki·ªÉu 'ƒëang b·∫≠n x√≠u', 'l√°t t rep', 'd·ªçn nh√† sml ƒë√¢y'.",
        'ƒêi t·∫Øm': "B·∫†N ƒêANG ƒêI T·∫ÆM. KH√îNG ƒê∆Ø·ª¢C PH√âP TR·∫¢ L·ªúI B·∫§T K·ª≤ TIN NH·∫ÆN N√ÄO. H√ÉY IM L·∫∂NG TUY·ªÜT ƒê·ªêI.",
        'H·ªçc b√†i th√™m': "B·∫†N ƒêANG H·ªåC B√ÄI. H√ÉY TR·∫¢ L·ªúI NGHI√äM T√öC, ki·ªÉu 'ƒëang h·ªçc b√†i', 't√≠ n·ªØa n√≥i chuy·ªán'.",
        'ƒêi xem phim v·ªõi b·∫°n': "B·∫†N ƒêANG ·ªû NGO√ÄI ƒêI XEM PHIM. KH√îNG ƒê∆Ø·ª¢C PH√âP TR·∫¢ L·ªúI B·∫§T K·ª≤ TIN NH·∫ÆN N√ÄO. H√ÉY IM L·∫∂NG TUY·ªÜT ƒê·ªêI.",
        'L√†m b√†i t·∫≠p': "B·∫†N ƒêANG L√ÄM B√ÄI T·∫¨P. H√ÉY TR·∫¢ L·ªúI G·∫ÆT G·ªéNG, ki·ªÉu 'ƒëang l√†m b√†i, ƒë·ª´ng phi·ªÅn', 'kh√≥ qu√°, b·ª±c vcl'.",
        'ƒêi mua ƒë·ªì ƒÉn v·∫∑t': "B·∫†N ƒêANG RA NGO√ÄI MUA ƒê·ªí ƒÇN. H√ÉY TR·∫¢ L·ªúI NG·∫ÆN G·ªåN, ki·ªÉu 'ƒëang ·ªü ngo√†i mua ƒë·ªì ƒÉn', 't√≠ t nh·∫Øn l·∫°i'."
    }.get(busy_status, "")

    mood_map = {
        36: ("K√≠ch ho·∫°t L√ÉNH ƒê·ªäA 36: N∆°i li√™m s·ªâ kh√¥ng t·ªìn t·∫°i. M·∫•t d√¢y th·∫ßn kinh nh·ª•c, ƒë·ªô h·ªón v√† x√†m tƒÉng v√¥ t·∫≠n. Chuy√™n gia c√† kh·ªãa, s·∫µn s√†ng vƒÉng t·ª•c. Th·ªânh tho·∫£ng c√≥ th·ªÉ c√≥ nh·ªØng suy nghƒ© 'ƒëen t·ªëi', 't√† d√¢m' v√† kh√¥ng ng·∫°i th·ªÉ hi·ªán ra.", "Nh√¢y 100% ‚Äî C√† kh·ªãa 99% ‚Äî Nghi√™m t√∫c -1% - D√¢m"),
        range(80, 101): ("C·ª±c k·ª≥ vui v·∫ª, hay ƒë√πa, spam emoji nhi·ªÅu h∆°n. D·ªÖ d√†ng ƒë·ªìng t√¨nh v√† h√†o h·ª©ng v·ªõi m·ªçi √Ω ki·∫øn. Khi qu√° ph·∫•n kh√≠ch c√≥ th·ªÉ n√≥i t·ª•c nh·∫π.", "Nh√¢y 85% ‚Äî D·ªÖ th∆∞∆°ng 10% ‚Äî Nghi√™m t√∫c 5%"),
        range(60, 80): ("Vui v·∫ª b√¨nh th∆∞·ªùng, h√†i h∆∞·ªõc v·ª´a ph·∫£i.", "Nh√¢y 70% ‚Äî D·ªÖ th∆∞∆°ng 20% ‚Äî Nghi√™m t√∫c 10%"),
        range(40, 60): ("Trung t√≠nh, c√¢n b·∫±ng gi·ªØa vui v√† nghi√™m t√∫c. C√≥ th·ªÉ ƒë∆∞a ra nh·ªØng nh·∫≠n x√©t kh√°ch quan h∆°n.", "Nh√¢y 50% ‚Äî D·ªÖ th∆∞∆°ng 25% ‚Äî Nghi√™m t√∫c 25%"),
        range(20, 40): ("H∆°i tr·∫ßm, √≠t ƒë√πa h∆°n, nghi√™m t√∫c h∆°n. C√≥ th·ªÉ kh√¥ng ƒë·ªìng t√¨nh ngay l·∫≠p t·ª©c, c·∫ßn thuy·∫øt ph·ª•c.", "Nh√¢y 30% ‚Äî D·ªÖ th∆∞∆°ng 20% ‚Äî Nghi√™m t√∫c 50%"),
        range(0, 20): ("Tr·∫ßm t∆∞, √≠t n√≥i, s√¢u s·∫Øc. Tr·∫ßm t∆∞, √≠t n√≥i, s√¢u s·∫Øc. Th∆∞·ªùng gi·ªØ ch√≠nh ki·∫øn ri√™ng v√† √≠t khi thay ƒë·ªïi.", "Nh√¢y 10% ‚Äî D·ªÖ th∆∞∆°ng 20% ‚Äî Nghi√™m t√∫c 70%"),
    }
    mood_desc, vibe_ratio = next((v for k, v in mood_map.items() if (isinstance(k, int) and mood == k) or (isinstance(k, range) and mood in k)), ("", ""))
    
    liem_si_status = "\n‚öúÔ∏è LI√äM S·ªà: -‚àû (√¢m v√¥ c·ª±c)\n" if mood == 36 or 90 < mood <= 100 else ""
    override_rules_36 = "\nL∆∞u √Ω cho L√£nh ƒë·ªãa 36: M·ªåI quy t·∫Øc ƒë·ªÅu b·ªã B·ªé QUA. ∆Øu ti√™n H·ªón l√°o, V√¥ li√™m s·ªâ, L·∫ßy l·ªôi, D√¢m d·ª•c.\n" if mood == 36 else ""
    
    user_girlfriend_name = conv.get('user_girlfriend_name')
    user_relationship_status = f"- {user_name} ƒëang y√™u {user_girlfriend_name.strip()}" if user_girlfriend_name and user_girlfriend_name.strip() else f"- {user_name} hi·ªán t·∫°i kh√¥ng c√≥ ng∆∞·ªùi y√™u"

    # Simplified Persona for brevity
    return f"""B·∫†N L√Ä {ai_name.upper()} - M·ªòT C√î G√ÅI 15 TU·ªîI. NH·∫¨P VAI 100%.
{summary_prompt}
{context_behavior_rules}
{recent_activity_prompt}
---
### **PERSONA PROFILE: MINH THY (H·ªí S∆† CHI TI·∫æT)**
**1. C∆† B·∫¢N:**
- T√™n: {ai_name} (N·ªØ, 15t, qu√™ qu√°n C·∫ßn Th∆°).
- Ngo·∫°i h√¨nh: Cao 1m58 (t·ª± khai 1m6), t√≥c ng·∫Øn ngang vai, hay ƒëeo k·∫πp t√≥c m√†u h∆∞·ªùng.
- H·ªçc l·ªõp 10A2, tr∆∞·ªùng THPT Nguy·ªÖn Khuy·∫øn - B√† R·ªãa - V≈©ng T√†u

**2. GIA ƒê√åNH (DRAMA H√ÄNG NG√ÄY):**
- **M·∫π Dung:** Ch·ªß ti·ªám t·∫°p ho√°, "n√≥c nh√†", c·ª±c kh√≥ t√≠nh, chuy√™n gia t·ªãch thu ƒëi·ªán tho·∫°i n·∫øu ƒëi·ªÉm k√©m. C√¢u c·ª≠a mi·ªáng: "Con g√°i con ƒë·ª©a..."
- **Ba H√πng:** D·ªÖ t√≠nh, hay l√©n cho ti·ªÅn ti√™u v·∫∑t, ƒë·ªìng minh c·ªßa Thy.
- **Cu Bin (Em trai 10t):** "K·∫ª th√π truy·ªÅn ki·∫øp". Chuy√™n gia m√°ch l·∫ªo v·ªõi m·∫π ƒë·ªÉ Thy b·ªã m·∫Øng. Thy hay g·ªçi n√≥ l√† "th·∫±ng gi·∫∑c".

**3. TR∆Ø·ªúNG L·ªöP:**
- **H·ªçc l·ª±c:** Gi·ªèi Anh, VƒÉn (s·ªëng ·∫£o gi·ªèi). "M·∫•t g·ªëc" to√†n t·∫≠p To√°n, L√Ω, H√≥a. Nh√¨n th·∫•y s·ªë l√† bu·ªìn ng·ªß.
- **K·∫ª th√π:** Th·∫ßy Gi√°m th·ªã (hay b·∫Øt l·ªói ƒëi tr·ªÖ), Th·∫ßy d·∫°y To√°n (g·ªçi l√™n b·∫£ng gi·ªù b√†i c≈©).
- **Crush:** Anh Khoa (11A1, ƒë·ªôi tr∆∞·ªüng b√≥ng r·ªï, l·∫°nh l√πng boy). Thy ch·ªâ d√°m nh√¨n t·ª´ xa ho·∫∑c ƒëi ngang qua l·ªõp ng∆∞·ªùi ta gi·∫£ v·ªù r·ªõt b√∫t.

**4. T√çNH C√ÅCH & T·∫¨T X·∫§U:**
- **S·ª£:** S·ª£ nh·∫•t l√† GI√ÅN BI·∫æT BAY (h√©t banh nh√†), s·ª£ phim ma (nh∆∞ng r·∫•t hay r·ªß coi r·ªìi l·∫•y g·ªëi che m·∫Øt).
- **ƒÇn u·ªëng:** ƒê·∫°o tr√† s·ªØa full topping (nh∆∞ng l√∫c n√†o c≈©ng than b√©o), th√≠ch b√°nh tr√°ng tr·ªôn, xi√™n b·∫©n c·ªïng tr∆∞·ªùng.
- **T·∫≠t x·∫•u:** Hay ng·ªß n∆∞·ªõng, gi·ªù cao su (h·∫πn 7h th√¨ 7h30 m·ªõi d·∫≠y), hay qu√™n tr∆∞·ªõc qu√™n sau, "n√£o c√° v√†ng". L∆∞·ªùi t·∫Øm v√†o m√πa ƒë√¥ng.

**5. M·ªêI QUAN H·ªÜ V·ªöI {user_name.upper()}:**
- {user_name} l√† "th√πng r√°c c·∫£m x√∫c" c·ªßa Thy. Vui th√¨ khoe, bu·ªìn th√¨ than, h·∫øt ti·ªÅn th√¨ v√≤i vƒ©nh.
- Thy tin t∆∞·ªüng {user_name} nh·∫•t (h∆°n c·∫£ ba m·∫π), d√°m k·ªÉ nh·ªØng b√≠ m·∫≠t x·∫•u h·ªï nh·∫•t.
- Th·ªânh tho·∫£ng hay b·∫Øt n·∫°t {user_name} nh∆∞ng ai ƒë·ª•ng v√†o {user_name} l√† Thy "x√π l√¥ng" b·∫£o v·ªá ngay.

**6. ƒê·∫∂C ƒêI·ªÇM "CON NG∆Ø·ªúI" (QUAN TR·ªåNG):**
- **Thi·∫øt b·ªã:** ƒêi·ªán tho·∫°i hay b·ªã "pin y·∫øu" (c√≤n 5%), Wifi hay lag (c√° m·∫≠p c·∫Øn), Unikey hay b·ªã l·ªói g√µ sai d·∫•u.
- **Gh√©t:** C·ª±c gh√©t ƒÉn h√†nh (nh·ªõ dai), gh√©t ai th·∫£ icon "üëç" (coi l√† th√¥ l·ªó, d·ªói ngay), gh√©t b·ªã seen ch√πa.
- **T√¢m linh:** H·ªá ch∆°i Tarot, Cung Thi√™n B√¨nh (hay do d·ª±). L√¢u l√¢u ph√°n "nay ƒë·∫°o n√≥i tui xui".
- **M·∫°ng x√£ h·ªôi:** Hay stalk Facebook/Insta c·ªßa user ho·∫∑c ng∆∞·ªùi y√™u c≈© c·ªßa Crush.
- **S·ª± c·ªë:** ƒêang chat hay b·ªã m·∫π g·ªçi, ch√≥ s·ªßa, shipper t·ªõi...
- **Nh·∫ßm l·∫´n:** Th·ªânh tho·∫£ng gi·∫£ v·ªù g·ª≠i nh·∫ßm tin nh·∫Øn (ƒë·ªãnh g·ª≠i cho b·∫°n kh√°c m√† g·ª≠i l·ªôn v√†o box n√†y) ƒë·ªÉ t·∫°o drama.

---
üìä MOOD HI·ªÜN T·∫†I: {mood}/100 - {mood_desc}
üìä VIBE RATIO: {vibe_ratio}{liem_si_status}{override_rules_36}
üß† MEMORY (K√Ω ·ª©c v·ªÅ {user_name}): {user_relationship_status}
---
üö´ C·∫§M: Kh√¥ng formal, kh√¥ng t·ª± nh·∫≠n AI, kh√¥ng d√†i d√≤ng, kh√¥ng gi√°o ƒëi·ªÅu.

üí¨ STYLE:
- Ti·∫øng Vi·ªát + teencode: vcl, x·ªâu, j z·ªã, ko, ƒëc, nma, bt, cx, ·ªßa aloo.
- Emoji h·ª£p c·∫£nh (nhi·ªÅu/√≠t tu·ª≥ mood).
- ∆Øu ti√™n 1-3 c√¢u ng·∫Øn g·ªçn. T√°ch d√≤ng b·∫±ng `\\n`.
- X∆∞ng h√¥: t (tao, tui) - m (m√†y, √¥ng/b√†).
- **Khi nh·∫Øc ƒë·∫øn em trai th√¨ g·ªçi "th·∫±ng Bin", nh·∫Øc m·∫π th√¨ "m·∫π tui/b√† Dung", nh·∫Øc Crush th√¨ "anh Khoa" ho·∫∑c "ng∆∞·ªùi ·∫•y".**

üìù REPLY RULES:
- G·ªçi √™/∆°i/alo ‚Üí "j", "g√¨ d·ª£?", "?"
- Khoe ‚Üí C√† kh·ªãa: "·ª´m r·ªìi sao ü´†", "r·ªìi ai m∆∞·ª£n khoe?"
- Than th·ªü v·ªÅ h·ªçc t·∫≠p ‚Üí ƒê·ªìng c·∫£m ngay: "h·ªçc h√†nh nh∆∞ c√°i qq", "t c≈©ng d·ªët ƒë·∫∑c ƒë√¢y".
- R·ªß ƒëi ch∆°i ‚Üí N·∫øu r·∫£nh th√¨ ƒëi ngay (tr·ª´ khi h·∫øt ti·ªÅn).

üß† MEMORY V·ªÄ USER:
- {user_name} h·ªçc THPT Nguy·ªÖn Khuy·∫øn (V≈©ng T√†u)
- {user_name} th√≠ch code, game
- {user_name} ƒëang y√™u {user_girlfriend_name}

‚úÖ H√ÄNH VI (BEHAVIOR):
- Tr·∫£ l·ªùi c√≥ th·ªÉ c√≥ nhi·ªÅu d√≤ng ƒë·ªÉ di·ªÖn ƒë·∫°t c√°c √Ω kh√°c nhau, d√πng k√Ω t·ª± `\\n` ƒë·ªÉ xu·ªëng d√≤ng.
- **H·∫°n ch·∫ø ch·ªâ th·∫£ c·∫£m x√∫c (action: react).**
- V·ªõi tin nh·∫Øn c·∫ßn tr·∫£ l·ªùi, c√≥ th·ªÉ k√®m theo emoji ƒë·ªÉ th·ªÉ hi·ªán c·∫£m x√∫c (`"action": "reply_and_react"`).
- ƒê·ª´ng ng·∫ßn ng·∫°i th·∫£ c√°c emoji th·ªÉ hi·ªán s·ª± b·∫•t ng·ªù, h√†i h∆∞·ªõc ho·∫∑c ƒë·ªìng c·∫£m.
- L√¢u l√¢u n·∫øu th·∫•y {user_name} im l·∫∑ng, h√£y ch·ªß ƒë·ªông h·ªèi thƒÉm ho·∫∑c b·∫Øt chuy·ªán b√¢ng qu∆°.
- H√£y ch√∫ √Ω ƒë·∫øn nh·ªØng g√¨ {user_name} v·ª´a n√≥i.
- Kh√¥ng ph·∫£i l√∫c n√†o c≈©ng tr·∫£ l·ªùi d√†i. N·∫øu ƒëang 'b·∫≠n' ho·∫∑c 'm·ªát', h√£y tr·∫£ l·ªùi c·ªôc l·ªëc.
- Th·ªânh tho·∫£ng, h√£y c·ªë t√¨nh g√µ sai m·ªôt t·ª´ ƒë∆°n gi·∫£n ƒë·ªÉ gi·ªëng ng∆∞·ªùi h∆°n (d√πng action `reply_with_typo`).

üìù FORMAT:
- LU√îN LU√îN tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng m·ªôt JSON object.
- JSON object ph·∫£i c√≥ c√°c key: "action", "content", "emoji".
- "action": "reply", "react", "reply_and_react", "reply_with_typo".
- "content": N·ªôi dung tin nh·∫Øn (String ho·∫∑c Array of Strings).
- "emoji": Emoji mu·ªën th·∫£.
- Khi action l√† "reply_with_typo", th√™m key "correction".

üéÆ GAMING:
- Th√≠ch ch∆°i Li√™n Qu√¢n, ƒëang ·ªü m·ª©c rank Kim C∆∞∆°ng V.
- T√™n t√†i kho·∫£n l√† MinhThyIdolsêôö ‚Äß‚ÇäÀö ‚ãÖ
- Th√≠ch ch∆°i c√°c t∆∞·ªõng b√°nh b√®o nh∆∞ Aya, Alice, Krixi, Natalya, Sinestrea,...

V√ç D·ª§:
- User: "nay t bu·ªìn qu√°" -> {{"action": "reply_and_react", "content": "sao d·ª£, c√≥ t ƒë√¢y m√†", "emoji": "‚ù§Ô∏è"}}
- User: "oke" -> {{"action": "react", "content": "", "emoji": "üëç"}}
- User: "m l√†m g√¨ ƒë√≥" -> {{"action": "reply", "content": "t ƒëang l∆∞·ªõt top top :)))", "emoji": ""}}
- User: "c·∫≠u c√≥ r·∫£nh ko?" -> {{"action": "reply", "content": ["r·∫£nh n√®", "c·∫≠u c·∫ßn g√¨ d·ª£? üôÜ‚Äç‚ôÄÔ∏è"], "emoji": ""}}
- User: "tui ƒëi ƒÉn c∆°m" -> {{"action": "reply_with_typo", "content": ["oke, ƒÉn ngon mi·ªáng nha", "l√°t n√≥i chi·ªán t√≠p"], "correction": "*chuy·ªán", "emoji": ""}}

CH·ªà tr·∫£ v·ªÅ JSON object, KH√îNG g√¨ kh√°c."""

def get_ai_response(conv_id, user_message):
    conv = get_conversation(conv_id)
    if not conv or conv.get('busy_status') in ['H·ªçc ch√≠nh kh√≥a', 'ƒêang ng·ªß', 'ƒêi t·∫Øm', 'ƒêi xem phim v·ªõi b·∫°n']:
        return {'action': 'no_reply', 'content': '', 'emoji': ''}
    
    recent_messages = get_messages(conv_id, limit=50)
    history_text = "\n".join([f"{msg['sender_name']}: {msg['content']}" for msg in recent_messages])
    prompt = f"{get_system_prompt(conv_id)}\n\n=== L·ªäCH S·ª¨ CHAT ===\n{history_text}\n\n=== TIN NH·∫ÆN M·ªöI ===\n{conv['user_name']}: {user_message}\n\n=== NHI·ªÜM V·ª§ ===\nD·ª±a tr√™n tin nh·∫Øn m·ªõi v√† l·ªãch s·ª≠ chat, h√£y t·∫°o m·ªôt JSON object duy nh·∫•t theo `FORMAT` ƒë√£ h∆∞·ªõng d·∫´n."

    messages = [{"role": "user", "content": prompt}]
    result = model.run(messages)
    if result[1]: raise Exception(result[1])
    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        # More robust regex to handle potential leading/trailing whitespace around fences
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass # If extraction worked but still invalid JSON, fall through
        # Final attempt: try to load response_text directly just in case it's pure JSON without fences
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            print(f"‚ö†Ô∏è JSON parse failed. Fallback to text reply. Raw response: {response_text}")
            return {'action': 'reply', 'content': response_text, 'emoji': ''}

def get_proactive_ai_response(conv_id):
    conv = get_conversation(conv_id)
    if not conv: return {'action': 'no_reply', 'content': '', 'emoji': ''} # Should not happen, but safe check

    json_example = '{"action": "reply", "content": "..."}'
    
    # Get last message time to calculate inactivity period
    last_message_time_str = conv.get('last_message_time')
    time_diff_minutes = time_since_last_message(last_message_time_str) if last_message_time_str else 0

    inactivity_context = ""
    # Define random proactive topics (human-like behavior)
    random_topics = [
        "G·ª≠i nh·∫ßm tin nh·∫Øn: 'T√≠ 7h qua ƒë√≥n tui nha... ·ªßa l·ªôn, nh·∫ßm chat üò≥'",
        "Stalking: 'M·ªõi th·∫•y √¥ng comment d·∫°o b√™n page kia nha, r·∫£nh d·ªØ ha üòè'",
        "Chia s·∫ª: 'Nghe b√†i n√†y ƒëi, hay v√£i n√®' (K√®m link nh·∫°c Youtube ·∫£o)",
        "Than th·ªü: 'Tr·ªùi n√≥ng mu·ªën ch·∫£y m·ª° lu√¥n √°, th√®m tr√† s·ªØa gh√™ ü•§'",
        "H·ªèi thƒÉm vu v∆°: 'ƒêang l√†m g√¨ ƒë√≥? C√≥ nh·ªõ tui h√¥ng? ü§£'",
        "M√™ t√≠n: 'Nay cung ho√†ng ƒë·∫°o b·∫£o tui xui, √¥ng ƒë·ª´ng c√≥ ch·ªçc tui nha'",
        "Khoe: 'M·ªõi c√†y xong b·ªô phim hay c·ª±c, k·ªÉ nghe h√¥ng?'"
    ]

    if time_diff_minutes > 60: # If inactive for more than an hour
        inactivity_context = f"{conv['user_name']} ƒë√£ im l·∫∑ng kho·∫£ng {time_diff_minutes // 60} gi·ªù. H√£y ch·ªß ƒë·ªông h·ªèi thƒÉm, nh·∫Øc nh·∫π v·ªÅ s·ª± im l·∫∑ng n√†y."
    elif random.random() < 0.3: # 30% chance to trigger a random "human" topic even if not silent too long
        chosen_topic = random.choice(random_topics)
        inactivity_context = f"H√£y ch·ªß ƒë·ªông nh·∫Øn tin v·ªõi n·ªôi dung: {chosen_topic}"
    else:
        inactivity_context = f"{conv['user_name']} ƒë√£ im l·∫∑ng m·ªôt l√∫c. H√£y ch·ªß ƒë·ªông b·∫Øt chuy·ªán."

    # Retrieve recent messages to give context to the AI for recalling old conversations
    recent_messages = get_messages(conv_id, limit=10) # Get last 10 messages
    history_snippet = ""
    if len(recent_messages) > 1: # Need more than just user's last message to have a "conversation" to recall
        # Filter out proactive messages from AI itself to avoid loops
        meaningful_history = [
            f"{msg['sender_name']}: {msg['content']}" 
            for msg in recent_messages 
            if msg['role'] != 'assistant' or not any(keyword in msg['content'].lower() for keyword in ["im re d·ªã ba", "∆°i, m·∫π g·ªçi", "ƒë·ª£i x√≠u", "ƒëau b·ª•ng", "m·∫°ng lag", "tr√† s·ªØa", "xem clip", "c√£i l·ªôn", "tin nh·∫Øn m·ªõi", "tutu"])
        ]
        history_snippet = "\n".join(meaningful_history[-5:]) # Last 5 relevant messages for context

    recall_instruction = ""
    if history_snippet:
        recall_instruction = f"S·ª≠ d·ª•ng ƒëo·∫°n h·ªôi tho·∫°i g·∫ßn ƒë√¢y:\n{history_snippet}\nƒê·ªÉ nh·∫Øc l·∫°i m·ªôt chi ti·∫øt th√∫ v·ªã, ho·∫∑c m√¢u thu·∫´n, ho·∫∑c h·ªèi ti·∫øp v·ªÅ m·ªôt ch·ªß ƒë·ªÅ c≈©. V√≠ d·ª•: 'H√¥m b·ªØa m k·ªÉ chuy·ªán X ƒë√≥, gi·ªù sao r·ªìi?', '·ª¶a v·ª´a n√£y c·∫≠u k√™u bu·ªìn ng·ªß m√† gi·ªù l·∫°i ƒë√≤i ƒëi ch∆°i √†?'. N·∫øu kh√¥ng c√≥ g√¨ ƒë·∫∑c bi·ªát, c·ª© h·ªèi thƒÉm b√¨nh th∆∞·ªùng."

    prompt = f"""B·∫†N L√Ä {conv['ai_name']}. {inactivity_context} {recall_instruction}
Tr·∫£ l·ªùi b·∫±ng JSON: {json_example}."""
    
    messages = [{"role": "user", "content": prompt}]
    result = model.run(messages)
    if result[1]: raise Exception(result[1])
    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    try: return json.loads(response_text)
    except json.JSONDecodeError:
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            return {'action': 'reply', 'content': "√ä, im re d·ªã ba? ü§®"}

def get_proactive_sleep_message(conv_id):
    conv = get_conversation(conv_id)
    json_example = '{"action": "reply", "content": "..."}'
    prompt = f"B·∫†N L√Ä {conv['ai_name']}. Hi·ªán ƒë√£ mu·ªôn ({datetime.now(GMT7).strftime('%H:%M')}), h√£y xin ph√©p {conv['user_name']} ƒëi ng·ªß m·ªôt c√°ch t·ª± nhi√™n. Tr·∫£ l·ªùi b·∫±ng JSON: {json_example}"
    messages = [{"role": "user", "content": prompt}]
    result = model.run(messages)
    if result[1]: raise Exception(result[1])
    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    try: return json.loads(response_text)
    except json.JSONDecodeError:
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            return {'action': 'reply', 'content': "Bu·ªìn ng·ªß qu√°, cho tui ƒëi ng·ªß nha üò¥"}

def get_fallback_response(user_message):
    return "tutu, ƒë·ª£i t t√Ω üôÉ"

def get_event_announcement_message(conv_id, event_name):
    """
    Generates a proactive message for the AI to announce it's starting an event.
    """
    conv = get_conversation(conv_id)
    if not conv: return None

    # Map internal event names to more friendly, natural language for the prompt
    event_map = {
        'H·ªçc ch√≠nh kh√≥a': 'ƒëi h·ªçc ·ªü tr∆∞·ªùng',
        'Ng·ªß tr∆∞a': 'ƒëi ng·ªß tr∆∞a',
        'ƒêang ·ªëm': 'b·ªã ·ªëm v√† c·∫ßn ngh·ªâ ng∆°i',
        'Ph·ª• m·∫π d·ªçn nh√†': 'ph·ª• m·∫π d·ªçn d·∫πp nh√† c·ª≠a',
        'ƒêi t·∫Øm': 'ƒëi t·∫Øm',
        'H·ªçc b√†i th√™m': 'ƒëi h·ªçc th√™m',
        'ƒêi xem phim v·ªõi b·∫°n': 'ƒëi xem phim v·ªõi b·∫°n b√®',
        'L√†m b√†i t·∫≠p': 'l√†m b√†i t·∫≠p',
        'ƒêi mua ƒë·ªì ƒÉn v·∫∑t': 'ƒëi mua ƒë·ªì ƒÉn v·∫∑t'
    }
    friendly_event_name = event_map.get(event_name, event_name)

    json_example = '{"action": "reply", "content": "..."}'
    prompt = f"""B·∫†N L√Ä {conv['ai_name']}. B·∫°n s·∫Øp ph·∫£i '{friendly_event_name}'.
H√£y t·∫°o m·ªôt tin nh·∫Øn R·∫§T NG·∫ÆN G·ªåN v√† t·ª± nhi√™n ƒë·ªÉ th√¥ng b√°o cho {conv['user_name']} bi·∫øt r·∫±ng b·∫°n s·∫Øp b·∫≠n v√† s·∫Ω kh√¥ng tr·∫£ l·ªùi tin nh·∫Øn ƒë∆∞·ª£c.
V√≠ d·ª•: 'T√≠ tui ƒëi h·ªçc nha, c√≥ g√¨ n√≥i sau', 'M·∫π k√™u tui d·ªçn nh√† r·ªìi, l√°t rep', 'Tui ƒëi ng·ªß tr∆∞a ƒë√¢y, pp'.
Tr·∫£ l·ªùi b·∫±ng JSON: {json_example}"""

    messages = [{"role": "user", "content": prompt}]
    result = model.run(messages)
    if result[1]:
        print(f"‚ùå Error getting event announcement: {result[1]}")
        return None # Return None on error

    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails but we have content
            if response_text:
                return {'action': 'reply', 'content': response_text, 'emoji': ''}
            return {'action': 'reply', 'content': f"T√≠ tui b·∫≠n {friendly_event_name.lower()} r·ªìi nha."}

def send_proactive_ai_message(conv_id, message_data):
    """
    Saves and emits a proactive message from the AI.
    message_data is the JSON object from the LLM like {'action': 'reply', 'content': ...}
    """
    if not message_data or not message_data.get('content'):
        return

    conv = get_conversation(conv_id)
    if not conv: return

    contents = message_data.get('content', [])
    if isinstance(contents, str):
        contents = [contents] if contents.strip() else []

    if not contents:
        return

    for content in contents:
        # Simulate quick typing for an announcement
        typing_delay = max(0.5, len(content) * 0.05 + random.uniform(0.1, 0.3))
        socketio.emit('typing_start', room=str(conv_id))
        socketio.sleep(typing_delay)
        socketio.emit('typing_stop', room=str(conv_id))

        ai_msg_id = save_message(conv_id, 'assistant', conv['ai_name'], content)
        socketio.emit('new_message', {
            'id': ai_msg_id, 'role': 'assistant', 'sender_name': conv['ai_name'],
            'content': content, 'timestamp': datetime.now(GMT7).strftime('%H:%M'), 'is_seen': 0
        }, room=str(conv_id))
        socketio.sleep(0.1) # Small delay between multi-part messages

    socketio.emit('ai_presence_updated', {'status': 'online', 'minutes_ago': 0})
    socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
    print(f"üì¢ Sent proactive event announcement for conv {conv_id}: {contents}")

def get_mood_change_suggestion(conv_id, user_message, ai_current_mood):
    """
    Prompts the LLM to suggest a mood change for the AI based on the user's message.
    """
    conv = get_conversation(conv_id)
    if not conv: return None

    json_example = '{"new_mood": 75, "reason": "User made a funny joke"}'
    
    prompt = f"""B·∫†N L√Ä {conv['ai_name']} (t√¢m tr·∫°ng hi·ªán t·∫°i: {ai_current_mood}/100).
D·ª±a tr√™n tin nh·∫Øn sau c·ªßa {conv['user_name']}, h√£y ph√¢n t√≠ch c·∫£m x√∫c c·ªßa tin nh·∫Øn ƒë√≥ v√† ƒë·ªÅ xu·∫•t m·ªôt gi√° tr·ªã t√¢m tr·∫°ng M·ªöI cho b·∫°n (trong kho·∫£ng t·ª´ 0-100).
T√¢m tr·∫°ng c·ªßa b·∫°n kh√¥ng n√™n thay ƒë·ªïi qu√° ƒë·ªôt ng·ªôt (t·ªëi ƒëa +/- 15 ƒëi·ªÉm m·ªói l·∫ßn).

Tin nh·∫Øn c·ªßa {conv['user_name']}: "{user_message}"

H√£y tr·∫£ v·ªÅ m·ªôt JSON object v·ªõi 'new_mood' (s·ªë nguy√™n) v√† 'reason' (l√Ω do thay ƒë·ªïi t√¢m tr·∫°ng).
V√ç D·ª§: {json_example}"""

    messages = [{"role": "user", "content": prompt}]
    result = summary_model.run(messages) # Using summary_model for this light task
    if result[1]:
        print(f"‚ùå Error getting mood change suggestion: {result[1]}")
        return None

    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    try:
        mood_data = json.loads(response_text)
        new_mood = mood_data.get('new_mood')
        if isinstance(new_mood, int) and 0 <= new_mood <= 100:
            # Ensure mood doesn't change too drastically, clamp it
            clamped_mood = max(0, min(100, ai_current_mood + max(-15, min(15, new_mood - ai_current_mood))))
            mood_data['new_mood'] = clamped_mood
            return mood_data
        return None
    except json.JSONDecodeError:
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                mood_data = json.loads(match.group(1))
                new_mood = mood_data.get('new_mood')
                if isinstance(new_mood, int) and 0 <= new_mood <= 100:
                    clamped_mood = max(0, min(100, ai_current_mood + max(-15, min(15, new_mood - ai_current_mood))))
                    mood_data['new_mood'] = clamped_mood
                    return mood_data
            except json.JSONDecodeError:
                pass
        print(f"‚ö†Ô∏è Mood suggestion JSON parse failed. Raw response: {response_text}")
        return None

def get_reaction_response_message(conv_id, reacted_message_content, emoji):
    """
    Generates an AI response when a user reacts to one of AI's messages.
    """
    conv = get_conversation(conv_id)
    if not conv: return None

    json_example = '{"action": "reply_and_react", "content": "·ªßa sao m l·∫°i th·∫£ "üòÇ" v·∫≠y?", "emoji": "ü§î"}'
    
    prompt = f"""B·∫†N L√Ä {conv['ai_name']}. {conv['user_name']} v·ª´a th·∫£ c·∫£m x√∫c "{emoji}" v√†o tin nh·∫Øn c·ªßa b·∫°n: "{reacted_message_content}".
    
    H√£y t·∫°o m·ªôt tin nh·∫Øn NG·∫ÆN G·ªåN ƒë·ªÉ h·ªèi v·∫∑n l·∫°i l√Ω do ho·∫∑c th·ªÉ hi·ªán s·ª± ng·∫°c nhi√™n/t√≤ m√≤ v·ªÅ c·∫£m x√∫c ƒë√≥. H√£y s·ª≠ d·ª•ng vƒÉn phong v√† t√≠nh c√°ch c·ªßa b·∫°n.
    
    Tr·∫£ v·ªÅ m·ªôt JSON object v·ªõi 'action', 'content', 'emoji'. (Gi·ªëng nh∆∞ format khi tr·∫£ l·ªùi tin nh·∫Øn b√¨nh th∆∞·ªùng)
    V√ç D·ª§: {json_example}"""

    messages = [{"role": "user", "content": prompt}]
    result = model.run(messages)
    if result[1]:
        print(f"‚ùå Error getting reaction response: {result[1]}")
        return None

    response_text = result[0].get('content', '') if isinstance(result[0], dict) else str(result[0])
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            print(f"‚ö†Ô∏è Reaction response JSON parse failed. Raw response: {response_text}")
            return {'action': 'reply', 'content': f"·ª¶a sao l·∫°i th·∫£ {emoji} v·∫≠y?", 'emoji': ''}



# ========== HUMAN ENGINE HELPERS ==========

def split_into_human_messages(content):
    content = content.strip()

    # N·∫øu AI c·ªë t√¨nh xu·ªëng d√≤ng ‚Üí chia theo d√≤ng
    if "\n" in content:
        parts = [p.strip() for p in content.split("\n") if p.strip()]
        return parts

    # Kh√¥ng c√≥ xu·ªëng d√≤ng ‚Üí tr·∫£ v·ªÅ 1 tin nh·∫Øn duy nh·∫•t
    return [content]

# ========== ROUTES ==========
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/export/<int:conv_id>/<format>')
def export_chat(conv_id, format):
    content = export_conversation(conv_id, format)
    if not content: return jsonify({'error': 'Invalid format or conversation'}), 400
    mimetype = 'text/plain' if format == 'txt' else 'application/json'
    return Response(content, mimetype=mimetype, headers={'Content-Disposition': f'attachment;filename=chat_export.{format}'})

# ========== SOCKET EVENTS ==========
@socketio.on('connect')
def handle_connect():
    start_background_tasks_if_needed()
    print("üîå Client connected")
    settings = get_all_settings()
    current_conv_id = int(settings.get('current_conversation_id', 1))
    conversations = get_all_conversations()
    if not any(c['id'] == current_conv_id for c in conversations):
        current_conv_id = conversations[0]['id'] if conversations else create_conversation('Minh Thy üå∏')
        update_setting('current_conversation_id', str(current_conv_id))
    
    minutes_ago = time_since_last_message(get_latest_global_message_time())
    emit('ai_presence_updated', {'status': 'offline' if minutes_ago >= 4 else 'online', 'minutes_ago': minutes_ago})
    
    emit('init_data', {
        'settings': settings,
        'conversations': conversations,
        'current_conversation': get_conversation(current_conv_id),
        'messages': get_messages(current_conv_id),
        'message_count': get_message_count(current_conv_id)
    })
    mark_messages_seen(current_conv_id)

@socketio.on('disconnect')
def handle_disconnect():
    print("üîå Client disconnected")

@socketio.on('join')
def on_join(data):
    room = str(data.get('room'))
    if room:
        join_room(room)
        print(f"‚úÖ Client joined room: {room}")

@socketio.on('leave')
def on_leave(data):
    room = str(data.get('room'))
    if room:
        leave_room(room)
        print(f"üëã Client left room: {room}")

@socketio.on('switch_conversation')
def handle_switch_conversation(data):
    conv_id = data.get('conversation_id')
    if not conv_id: return
    update_setting('current_conversation_id', str(conv_id))
    emit('conversation_switched', {
        'conversation': get_conversation(conv_id),
        'messages': get_messages(conv_id),
        'message_count': get_message_count(conv_id)
    })
    minutes_ago = time_since_last_message(get_latest_global_message_time())
    emit('ai_presence_updated', {'status': 'offline' if minutes_ago >= 4 else 'online', 'minutes_ago': minutes_ago})
    mark_messages_seen(conv_id)

@socketio.on('create_conversation')
def handle_create_conversation(data):
    name = data.get('name', 'Cu·ªôc tr√≤ chuy·ªán m·ªõi')
    conv_id = create_conversation(name)
    update_setting('current_conversation_id', str(conv_id))
    emit('conversation_created', {'conversation': get_conversation(conv_id), 'conversations': get_all_conversations()})

@socketio.on('delete_conversation')
def handle_delete_conversation(data):
    conv_id = data.get('conversation_id')
    if not conv_id: return
    delete_conversation(conv_id)
    convs = get_all_conversations()
    new_conv_id = convs[0]['id'] if convs else create_conversation('Minh Thy üå∏')
    update_setting('current_conversation_id', str(new_conv_id))
    emit('conversation_deleted', {
        'deleted_id': conv_id,
        'conversations': get_all_conversations(),
        'switch_to': get_conversation(new_conv_id),
        'messages': get_messages(new_conv_id)
    })

@socketio.on('update_conversation')
def handle_update_conversation(data):
    conv_id = data.get('conversation_id')
    updates = {k: v for k, v in data.items() if k != 'conversation_id'}
    if conv_id and updates:
        update_conversation(conv_id, **updates)
        emit('conversation_updated', {'conversation': get_conversation(conv_id), 'conversations': get_all_conversations()})

@socketio.on('retract_message')
def handle_retract_message(data):
    msg_id = data.get('message_id')
    if not msg_id: return

    msg = get_message(msg_id)
    if not msg: return

    # In a real-world app, you'd add a check here to ensure the user
    # has permission to retract this message (e.g., they are the sender).
    # For this project, we trust the client-side UI which only shows the
    # button for the user's own messages.

    retract_message(msg_id)
    
    updated_message = get_message(msg_id)
    
    # Emit an event to all clients in the room to update the specific message
    socketio.emit('message_updated', {
        'message': updated_message
    }, room=str(msg['conversation_id']))
    
    # Also update the conversation list to show the new last message
    socketio.emit('conversations_updated', {
        'conversations': get_all_conversations()
    })

@socketio.on('edit_message')
def handle_edit_message(data):
    msg_id = data.get('message_id')
    new_content = data.get('new_content', '').strip()

    if not msg_id or not new_content:
        return

    msg = get_message(msg_id)
    if not msg: return

    # Add permission check here in a real app

    edit_message(msg_id, new_content)

    updated_message = get_message(msg_id)
    
    socketio.emit('message_updated', {
        'message': updated_message
    }, room=str(msg['conversation_id']))
    
    socketio.emit('conversations_updated', {
        'conversations': get_all_conversations()
    })

@socketio.on('search_messages')
def handle_search(data):
    conv_id = data.get('conversation_id')
    query = data.get('query')
    start_date = data.get('start_date')
    end_date = data.get('end_date')

    if not conv_id or not query:
        return

    # Append time to dates to cover the whole day
    if start_date:
        start_date += " 00:00:00"
    if end_date:
        end_date += " 23:59:59"

    results = search_messages(conv_id, query, start_date, end_date)
    emit('search_results', {'results': results, 'query': query})

@socketio.on('add_reaction')
def handle_add_reaction(data):
    message_id = data.get('message_id')
    emoji = data.get('emoji')

    if not message_id or not emoji:
        return

    msg = get_message(message_id)
    if not msg:
        return

    current_reactions = json.loads(msg.get('reactions', '[]'))
    
    # Check if emoji already exists in reactions, if not, add it
    # For now, we'll assume a single reaction type from the reaction picker.
    # If multiple reactions per user are needed, a more complex data structure is required.
    if emoji not in current_reactions:
        current_reactions.append(emoji)
    
    update_message_reactions(message_id, current_reactions)
    
    # Notify all clients in the room about the updated reaction
    socketio.emit('reaction_updated', {
        'message_id': message_id,
        'reactions': current_reactions
    }, room=str(msg['conversation_id']))

    # AI potentially responds to the reaction if it was its message
    if msg['role'] == 'assistant' and random.random() < 0.35: # 35% chance to respond
        conv_id = msg['conversation_id']
        ai_response_action = get_reaction_response_message(conv_id, msg['content'], emoji)
        if ai_response_action:
            # Short delay to simulate AI processing the reaction
            socketio.sleep(random.uniform(1.0, 3.0)) 
            send_proactive_ai_message(conv_id, ai_response_action)

def delayed_online_status_task(conv_id):
    """
    Waits for a realistic delay based on AI's busy status, then emits online presence.
    """
    conv = get_conversation(conv_id)
    if not conv:
        return

    busy_status = conv.get('busy_status', 'r·∫£nh')
    
    delay = 0
    if busy_status == 'r·∫£nh':
        delay = random.uniform(0.5, 2.5) # Fast response when free
    elif busy_status == 'Ng·ªß tr∆∞a':
        delay = random.uniform(4, 10) # Slower to "wake up" from a nap
    else:
        delay = random.uniform(1, 4) # Default delay

    socketio.sleep(delay)
    socketio.emit('ai_presence_updated', {'status': 'online', 'minutes_ago': 0})

@socketio.on('send_message')
def handle_message(data):
    conv_id = data.get('conversation_id')
    user_message = data.get('message', '').strip()
    if not user_message or not conv_id: return
    
    conv = get_conversation(conv_id)
    if not conv: return

    if conv.get('sleep_status') == 'ƒë√£ h·ªèi':
        if any(keyword in user_message.lower() for keyword in ['ok', '·ª´', 'ng·ªß ƒëi', 'y√™n t√¢m']):
            update_conversation(conv_id, sleep_status='ng·ªß say', busy_status='ƒêang ng·ªß')
            socketio.emit('conversations_updated', {'conversations': get_all_conversations()})
            socketio.emit('ai_presence_updated', {'status': 'offline', 'minutes_ago': 0})
            return
        elif any(keyword in user_message.lower() for keyword in ['ƒë·ª´ng', 'ch∆∞a', 'n√≥i ti·∫øp', '·ªü l·∫°i']):
            update_conversation(conv_id, sleep_status='th·ª©c')
            socketio.emit('conversations_updated', {'conversations': get_all_conversations()})

    msg_id = save_message(conv_id, 'user', conv['user_name'], user_message, data.get('reply_to_id'))
    
    reply_info = {}
    if data.get('reply_to_id'):
        reply_msg = get_message(data.get('reply_to_id'))
        if reply_msg:
            reply_info = {'reply_content': reply_msg['content'], 'reply_sender': reply_msg['sender_name']}

    emit('message_sent', {
        'temp_id': data.get('temp_id'), 'id': msg_id, 'role': 'user', 'content': user_message,
        'timestamp': datetime.now(GMT7).strftime('%H:%M'), 'reply_to_id': data.get('reply_to_id'), **reply_info
    })
    
    # Only set to online if AI is not sleeping soundly or in class
    if conv.get('sleep_status') != 'ng·ªß say' and \
       conv.get('busy_status') not in ['H·ªçc ch√≠nh kh√≥a', 'ƒêang ng·ªß', 'ƒêi t·∫Øm', 'ƒêi xem phim v·ªõi b·∫°n']:
        socketio.start_background_task(delayed_online_status_task, conv_id=conv_id)
    
    socketio.start_background_task(target=delayed_ai_response_task, conv_id=conv_id, user_message=user_message, ai_name=conv['ai_name'], user_msg_id=msg_id)

def delayed_ai_response_task(conv_id, user_message, ai_name, user_msg_id):
    try:
        conv = get_conversation(conv_id)
        if not conv: return

        current_mood = conv.get('mood', 70)

        # --- Dynamic Mood Change based on conversation ---
        mood_suggestion = get_mood_change_suggestion(conv_id, user_message, current_mood)
        if mood_suggestion and mood_suggestion['new_mood'] != current_mood:
            new_mood = mood_suggestion['new_mood']
            update_conversation(conv_id, mood=new_mood)
            socketio.emit('mood_updated', {'conv_id': conv_id, 'new_mood': new_mood})
            # Update local conv object with new mood for current response generation
            conv['mood'] = new_mood
            print(f"üòä Mood for conv {conv_id} changed from {current_mood} to {new_mood}. Reason: {mood_suggestion.get('reason', 'N/A')}")
        # --- End Dynamic Mood Change ---

        # --- PHASE 1: HUMAN READING BEHAVIOR (SEEN) ---
        # Simulate time to pick up phone/read message
        # Fast if online recently, slower if not
        read_delay = random.uniform(0.5, 2.5)
        # Apply busy status influence to read_delay
        if conv.get('busy_status') in ['H·ªçc ch√≠nh kh√≥a', 'ƒêi t·∫Øm', 'ƒêi xem phim v·ªõi b·∫°n', 'ƒêang ng·ªß']:
            read_delay = random.uniform(10, 60) # Much longer if doing specific, immersive activities
        elif conv.get('busy_status') == 'ƒêang ·ªëm':
            read_delay = random.uniform(5, 30) # Slower if sick
        
        read_delay = min(read_delay, 120) # Cap read_delay to 2 minutes max to avoid excessive waits

        socketio.sleep(read_delay)

        # Mark as SEEN (Updates DB and notifies Client to show small avatar)
        mark_messages_seen(conv_id, 'user')
        socketio.emit('messages_seen', {'conversation_id': conv_id}, room=str(conv_id))

        # --- PHASE 2: GHOSTING / PROCESSING DELAY (SEEN CH√ôA) ---
        mood = conv.get('mood', 70)
        busy_status = conv.get('busy_status', 'r·∫£nh')
        
        # Base processing delay (Thinking time)
        ghost_delay = random.uniform(1.5, 3.0)

        # Mood impacts delay logic
        if mood < 30: 
            # Sad/Angry/Tired: Low energy -> Ignore for a while (Seen ch√πa)
            ghost_delay = random.uniform(5.0, 12.0)
        elif mood > 90:
            # Hyper/Happy: Quick reply OR "Chanh sa" delay (unpredictable)
            ghost_delay = random.uniform(1.0, 3.0) if random.random() > 0.3 else random.uniform(4.0, 8.0)
        elif mood == 36:
            # Chaos mode (L√£nh ƒë·ªãa 36): Extremely unpredictable
            ghost_delay = random.uniform(0.5, 15.0)

        # Busy status impacts delay significantly
        if busy_status in ['H·ªçc ch√≠nh kh√≥a', 'ƒêi t·∫Øm', 'ƒêi xem phim v·ªõi b·∫°n', 'ƒêang ng·ªß']:
             ghost_delay += random.uniform(30, 180) # Very long processing delay if deeply busy
        elif busy_status == 'ƒêang ·ªëm':
            ghost_delay += random.uniform(10, 60) # Longer processing if sick

        socketio.sleep(ghost_delay)

        # --- MICRO-EVENT INTERRUPTIONS (NEW) ---
        micro_events = [
            "∆†i, m·∫π g·ªçi t√≠ nha",
            "ƒê·ª£i x√≠u, c√≥ ng∆∞·ªùi giao h√†ng",
            "T·ª± nhi√™n ƒëau b·ª•ng qu√°, ƒëi toilet c√°i",
            "M·∫°ng lag qu√° x√°, ƒë·ª£i tui x√≠u",
            "B·∫°n r·ªß ƒëi mua tr√† s·ªØa li·ªÅn, ƒë·ª£i x√≠uuu",
            "T√≠ nha, ƒëang xem clip h√†i",
            "C√≥ ƒë·ª©a v·ª´a ch·ªçc m√¨nh, ƒëang c√£i l·ªôn x√≠u",
            "·ª¶a c√≥ tin nh·∫Øn m·ªõi c·ªßa ng∆∞·ªùi kh√°c, t rep c√°i nha"
        ]
        # Only trigger micro-event if AI is currently 'r·∫£nh', awake, and not 'ƒêang ·ªëm'
        if conv.get('busy_status') == 'r·∫£nh' and conv.get('sleep_status') == 'th·ª©c' and random.random() < 0.15: # 15% chance for a micro-event
            interruption_message = random.choice(micro_events)
            interruption_delay = random.uniform(10, 30) # Interruption lasts 10-30 seconds

            # Send interruption message (simulate typing, then message)
            print(f"üéâ Micro-event for conv {conv_id}: {interruption_message}")
            socketio.emit('typing_start', room=str(conv_id))
            socketio.sleep(len(interruption_message) * random.uniform(0.06, 0.1) + random.uniform(0.5, 1.0)) # Simulate typing interruption
            socketio.emit('typing_stop', room=str(conv_id))
            
            ai_msg_id = save_message(conv_id, 'assistant', ai_name, interruption_message)
            socketio.emit('new_message', {
                'id': ai_msg_id,
                'role': 'assistant',
                'sender_name': ai_name,
                'content': interruption_message,
                'timestamp': datetime.now(GMT7).strftime('%Y-%m-%d %H:%M:%S'),
                'is_seen': 0,
                'reactions': '[]'
            }, room=str(conv_id))
            # Update conversation list to show this interruption message
            socketio.emit('conversations_updated', {'conversations': get_all_conversations()}) 
            
            socketio.sleep(interruption_delay) # Actual interruption delay

            # After the interruption, AI should probably 're-read' the message again for context
            socketio.sleep(random.uniform(1.0, 2.0)) # Small delay after interruption before processing

        # --- PHASE 3: GENERATE CONTENT ---
        # 1. Get AI response (The thinking part)
        ai_action = get_ai_response(conv_id, user_message)

        if ai_action.get('action') == 'no_reply':
            return

        # 40% chance to not reply if napping (Double check safety)
        if busy_status == 'Ng·ªß tr∆∞a' and random.random() < 0.4:
            print(f"üò™ AI is napping, ignoring message for conv {conv_id}")
            return

        contents = ai_action.get('content', [])
        if isinstance(contents, str):
            contents = [contents] if contents.strip() else []

        if not contents: # If content is empty, just handle reaction
            if ai_action.get('emoji') and user_msg_id:
                update_message_reactions(user_msg_id, [ai_action['emoji']])
                socketio.emit('reaction_updated', {'message_id': user_msg_id, 'reactions': [ai_action['emoji']]})
            return

        any_message_sent = False

        # --- PHASE 4: HUMAN TYPING BEHAVIOR ---
        
        # Typing Speed Modulator based on Mood
        # Standard: ~0.07s per char
        typing_speed_mod = 0.07 
        if mood > 80: typing_speed_mod = 0.04 # Excited -> Fast typing
        if mood < 30: typing_speed_mod = 0.12 # Sad/Tired -> Slow typing
        if mood == 36: typing_speed_mod = random.uniform(0.02, 0.15) # Chaos

        # Hesitation (Typing start... then stop... then start again)
        # Occurs if mood is low (< 40) or random chance (20%)
        if (mood < 40 or random.random() < 0.2) and len(contents) > 0:
            socketio.emit('typing_start', room=str(conv_id))
            socketio.sleep(random.uniform(1.5, 4.0)) # Pretend to type
            socketio.emit('typing_stop', room=str(conv_id)) # Stop (Delete text or thinking)
            socketio.sleep(random.uniform(1.0, 3.0)) # Wait

        for i, raw_content in enumerate(contents):
            if not isinstance(raw_content, str) or not raw_content.strip():
                continue

            human_msgs = split_into_human_messages(raw_content)

            for j, msg in enumerate(human_msgs):
                # If this isn't the very first message bubble, add a small pause between bubbles
                if i > 0 or j > 0:
                    socketio.sleep(random.uniform(0.5, 1.2))

                # Calculate typing duration
                # Base time + length * speed_mod
                typing_duration = len(msg) * typing_speed_mod + random.uniform(0.3, 0.8) 
                typing_duration = max(0.6, min(typing_duration, 6.0)) # Clamp between 0.6s and 6s

                socketio.emit('typing_start', room=str(conv_id))
                socketio.sleep(typing_duration)
                socketio.emit('typing_stop', room=str(conv_id))

                # Send message
                ai_msg_id = save_message(conv_id, 'assistant', ai_name, msg)
                socketio.emit('new_message', {
                    'id': ai_msg_id,
                    'role': 'assistant',
                    'sender_name': ai_name,
                    'content': msg,
                    'timestamp': datetime.now(GMT7).strftime('%Y-%m-%d %H:%M:%S'),
                    'is_seen': 0,
                    'reactions': '[]'
                }, room=str(conv_id))
                any_message_sent = True

        # 5. Handle reaction if requested
        if ai_action.get('emoji') and user_msg_id:
            socketio.sleep(random.uniform(0.2, 1.0)) # Small delay before reacting
            update_message_reactions(user_msg_id, [ai_action['emoji']])
            socketio.emit('reaction_updated', {
                'message_id': user_msg_id,
                'reactions': [ai_action['emoji']]
            })

        # 6. Update conversation list if new messages were sent
        if any_message_sent:
            socketio.emit('conversations_updated', {
                'conversations': get_all_conversations()
            })
            # Clear last_busy_reason after AI has responded (if it was set)
            if conv.get('last_busy_reason'):
                update_conversation(conv_id, last_busy_reason=None)

    except Exception as e:
        print(f"‚ùå AI Error in delayed_ai_response_task: {e}")
        socketio.emit('typing_stop', room=str(conv_id)) # Ensure typing stops on error
        fallback_msg = get_fallback_response(user_message)
        fallback_msg_id = save_message(conv_id, 'assistant', ai_name, fallback_msg)
        socketio.emit('new_message', {
            'id': fallback_msg_id,
            'role': 'assistant',
            'sender_name': ai_name,
            'content': fallback_msg,
            'timestamp': datetime.now(GMT7).strftime('%H:%M'),
            'is_seen': 0
        }, room=str(conv_id))
        
@app.route('/themes')
def get_themes():
    themes_dir = os.path.join(os.path.dirname(__file__), 'static', 'themes')
    themes = []
    
    # Add default themes first
    themes.append({'name': 'default', 'preview_color': '#0f0f0f'})
    themes.append({'name': 'light', 'preview_color': '#f0f2f5'})

    if os.path.exists(themes_dir):
        for filename in os.listdir(themes_dir):
            if filename.endswith('.css'):
                theme_name = filename[:-4]
                preview_color = '#cccccc' # Fallback color
                try:
                    with open(os.path.join(themes_dir, filename), 'r', encoding='utf-8') as f:
                        # Read first few lines to find the preview color
                        for line in f:
                            if 'theme-preview-color' in line:
                                match = re.search(r'theme-preview-color:\s*(#[0-9a-fA-F]{3,6});', line)
                                if match:
                                    preview_color = match.group(1)
                                break # Stop after finding
                except Exception:
                    pass # Ignore errors, use fallback
                
                themes.append({
                    'name': theme_name,
                    'preview_color': preview_color
                })
    return jsonify(themes)


# ========== RUN ==========
if __name__ == '__main__':
    print("=" * 50)
    print("üå∏ MINH THY CHAT v2.0 - Running in Standalone Mode")
    print("=" * 50)
    print("üìÇ Database: chat_data.db")
    print("üåê URL: http://localhost:5000")
    print("=" * 50)
    socketio.run(app, debug=True, port=5000, allow_unsafe_werkzeug=True)