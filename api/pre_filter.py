# api/pre_filter.py
import os
import random
import asyncio
from bytez import Bytez

# Import get_dynamic_config tá»« api.utils Ä‘á»ƒ Ä‘á»c cáº¥u hÃ¬nh Ä‘á»™ng
from api.utils import get_dynamic_config

# Láº¥y cáº¥u hÃ¬nh tá»« biáº¿n mÃ´i trÆ°á»ng (chá»‰ cÃ²n láº¡i BYETZ_API_KEYS_STR)
# PRE_FILTER_MODEL_ID sáº½ Ä‘Æ°á»£c Ä‘á»c tá»« config.json

# Sá»­ dá»¥ng láº¡i danh sÃ¡ch API keys cá»§a Bytez Ä‘Ã£ cÃ³
BYTEZ_API_KEYS_STR = os.environ.get('BYTEZ_API_KEY')
if not BYTEZ_API_KEYS_STR:
    BYTEZ_API_KEYS = []
else:
    BYTEZ_API_KEYS = [key.strip() for key in BYTEZ_API_KEYS_STR.split(',') if key.strip()]

def create_pre_filter_prompt(text: str) -> str:
    """Táº¡o prompt cho model lá»c nhanh."""
    return (
        f"Is the following user message trivial, a simple greeting, an expression of thanks, "
        f"or conversational filler that does not require security analysis? "
        f"The message might be in Vietnamese. "
        f"Respond with only the single word 'true' if it is trivial, and 'false' otherwise.\n\n"
        f"Message: \"{text}\""
    )

async def is_trivial_message(text: str) -> bool:
    """
    Sá»­ dá»¥ng má»™t model AI nhá» Ä‘á»ƒ kiá»ƒm tra xem tin nháº¯n cÃ³ pháº£i lÃ  tin nháº¯n rÃ¡c,
    quÃ¡ Ä‘Æ¡n giáº£n Ä‘á»ƒ phÃ¢n tÃ­ch hay khÃ´ng.
    """
    # KhÃ´ng phÃ¢n tÃ­ch cÃ¡c tin nháº¯n quÃ¡ dÃ i báº±ng bá»™ lá»c nÃ y
    if len(text) > 100 or len(text.split()) > 15:
        return False
        
    if not BYTEZ_API_KEYS:
        print("ğŸ”´ [Pre-filter] Lá»—i: BYTEZ_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p, khÃ´ng thá»ƒ cháº¡y bá»™ lá»c nhanh.")
        return False # Máº·c Ä‘á»‹nh lÃ  khÃ´ng pháº£i tin nháº¯n rÃ¡c náº¿u khÃ´ng cÃ³ key

    try:
        # Äá»c PRE_FILTER_MODEL_ID tá»« config.json
        config = get_dynamic_config()
        pre_filter_model_id = config.get('pre_filter_model_id', 'openai/gpt-3.5-turbo') # Máº·c Ä‘á»‹nh lÃ  gpt-3.5-turbo
        
        selected_key = random.choice(BYTEZ_API_KEYS)
        sdk = Bytez(selected_key)
        model = sdk.model(pre_filter_model_id) # Sá»­ dá»¥ng model tá»« config.json
        
        prompt = create_pre_filter_prompt(text)
        
        print(f"â¡ï¸  [Pre-filter] Äang kiá»ƒm tra tin nháº¯n Ä‘Æ¡n giáº£n vá»›i {pre_filter_model_id}...")
        
        res = await asyncio.to_thread(
            model.run,
            [{"role": "user", "content": prompt}]
        )

        if res.error:
            print(f"ğŸ”´ [Pre-filter] Lá»—i tá»« Bytez SDK: {res.error}. Bá» qua bá»™ lá»c.")
            return False

        output = res.output
        if isinstance(output, dict) and "content" in output:
            response_text = output['content'].strip().lower()
            print(f"âœ… [Pre-filter] Model lá»c tráº£ vá»: '{response_text}'")
            return response_text == 'true'
        else:
            print(f"ğŸ”´ [Pre-filter] Äá»‹nh dáº¡ng output khÃ´ng mong muá»‘n. Bá» qua bá»™ lá»c.")
            return False

    except Exception as e:
        print(f"ğŸ”´ [Pre-filter] Lá»—i ngoáº¡i lá»‡: {e}. Bá» qua bá»™ lá»c.")
        return False # Náº¿u cÃ³ lá»—i, coi nhÆ° khÃ´ng pháº£i tin rÃ¡c Ä‘á»ƒ phÃ¢n tÃ­ch sÃ¢u hÆ¡n
